{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know which models are performing better, it's time to perform cross validation and tune hyperparameters.\n",
    "- Do a google search for hyperparameter ranges for each type of model.\n",
    "\n",
    "GridSearch/RandomSearch are a great methods for checking off both of these tasks.\n",
    "- BUT we have a problem - if we calculated a numerical value to encode city (such as the mean of sale prices in that city) on the training data, we can't cross validate \n",
    "- The rows in each validation fold were part of the original calculation of the mean for that city - that means we're leaking information!\n",
    "- While sklearn's built in functions are extremely useful, sometimes it is necessary to do things ourselves\n",
    "\n",
    "You need to create two functions to replicate what Gridsearch does under the hood\n",
    "\n",
    "**`custom_cross_validation()`**\n",
    "- Should take the training data, and divide it into multiple train/validation splits. \n",
    "- Look into `sklearn.model_selection.KFold` to accomplish this - the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) shows how to split a dataframe and loop through the indexes of your split data. \n",
    "- Within your function, you should compute the city means on the training folds just like you did in Notebook 1 - you may have to re-join the city column to do this - and then join these values to the validation fold\n",
    "\n",
    "**`hyperparameter_search()`**\n",
    "- Should take the validation and training splits from your previous function, along with your dictionary of hyperparameter values\n",
    "- For each set of hyperparameter values, fit your chosen model on each set of training folds, and take the average of your chosen scoring metric. [itertools.product()](https://docs.python.org/3/library/itertools.html) will be helpful for looping through all combinations of hyperparameter values\n",
    "- Your function should output the hyperparameter values corresponding the highest average score across all folds. Alternatively, it could also output a model object fit on the full training dataset with these parameters.\n",
    "\n",
    "Docstrings have been provided below to get you started. Once you're done developing your functions, you should move them to `functions_variables.py` to keep your notebook clean \n",
    "\n",
    "Bear in mind that these instructions are just one way to tackle this problem - the inputs and output formats don't need to be exactly as specified here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def custom_cross_validation(training_data, n_splits=5):\n",
    "    # Initialize KFold\n",
    "\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "\n",
    "    # Lists to store training and validation folds\n",
    "\n",
    "    training_folds = []\n",
    "    validation_folds = []\n",
    "    \n",
    "    # Iterate over each fold\n",
    "\n",
    "    for train_index, val_index in kf.split(training_data):\n",
    "        # Split data into train and validation sets\n",
    "\n",
    "        train_fold = training_data.iloc[train_index]\n",
    "        val_fold = training_data.iloc[val_index]\n",
    "        \n",
    "        # Compute city means on the training fold\n",
    "\n",
    "        city_means = train_fold.groupby('city')['list_price'].mean().reset_index()\n",
    "        city_means.columns = ['city', 'city_mean']\n",
    "        \n",
    "        # Join city means to validation fold\n",
    "\n",
    "        val_fold = pd.merge(val_fold, city_means, on='city', how='left')\n",
    "        \n",
    "        # Append training and validation folds to lists\n",
    "        \n",
    "        training_folds.append(train_fold)\n",
    "        validation_folds.append(val_fold)\n",
    "    \n",
    "    return training_folds, validation_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def hyperparameter_search(training_folds, validation_folds, hyperparameter_values, model):\n",
    "    # Initialize variables to store best hyperparameters and corresponding score\n",
    "\n",
    "    best_hyperparameters = None\n",
    "    best_score = float('-inf')\n",
    "    \n",
    "    # Loop through all combinations of hyperparameter values\n",
    "\n",
    "    for hyperparameters in itertools.product(*hyperparameter_values.values()):\n",
    "        # Create a dictionary of hyperparameter names and values\n",
    "        \n",
    "        hyperparameter_dict = dict(zip(hyperparameter_values.keys(), hyperparameters))\n",
    "        \n",
    "        # Initialize variable to store average score across folds\n",
    "\n",
    "        average_score = 0\n",
    "        \n",
    "        # Iterate over each fold\n",
    "\n",
    "        for train_fold, val_fold in zip(training_folds, validation_folds):\n",
    "            # Extract features and target from training and validation folds\n",
    "\n",
    "            X_train = train_fold.drop(columns=['target'])\n",
    "            y_train = train_fold['target']\n",
    "            X_val = val_fold.drop(columns=['target'])\n",
    "            y_val = val_fold['target']\n",
    "            \n",
    "            # Create model instance with current hyperparameters\n",
    "\n",
    "            current_model = model(**hyperparameter_dict)\n",
    "            \n",
    "            # Fit model on training data\n",
    "\n",
    "            current_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions on validation data\n",
    "\n",
    "            y_pred = current_model.predict(X_val)\n",
    "            \n",
    "            # Calculate score using chosen metric (e.g., mean squared error)\n",
    "\n",
    "            score = mean_squared_error(y_val, y_pred) \n",
    "            \n",
    "            # Update average score\n",
    "\n",
    "            average_score += score / len(validation_folds)\n",
    "        \n",
    "        # Check if current hyperparameters yield a better score\n",
    "        \n",
    "        if average_score > best_score:\n",
    "            best_score = average_score\n",
    "            best_hyperparameters = hyperparameter_dict\n",
    "    \n",
    "    return best_hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_validation_svr(training_data, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    svr_training_folds = []\n",
    "    svr_validation_folds = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(training_data):\n",
    "        train_fold = training_data.iloc[train_index]\n",
    "        val_fold = training_data.iloc[val_index]\n",
    "        \n",
    "        city_means = train_fold.groupby('city')['target'].mean().reset_index()\n",
    "        city_means.columns = ['city', 'city_mean']\n",
    "        \n",
    "        val_fold = pd.merge(val_fold, city_means, on='city', how='left')\n",
    "        \n",
    "        svr_training_folds.append(train_fold)\n",
    "        svr_validation_folds.append(val_fold)\n",
    "    \n",
    "    return svr_training_folds, svr_validation_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def hyperparameter_search_svr(training_folds, validation_folds, param_grid):\n",
    "    best_hyperparameters = None\n",
    "    best_score = float('-inf')\n",
    "    \n",
    "    for params in itertools.product(*param_grid.values()):\n",
    "        total_score = 0\n",
    "        for i in range(len(training_folds)):\n",
    "            model = SVR(**dict(zip(param_grid.keys(), params)))\n",
    "            model.fit(training_folds[i].drop(columns=['target', 'city']), training_folds[i]['target'])\n",
    "            y_pred = model.predict(validation_folds[i].drop(columns=['target', 'city']))\n",
    "            score = r2_score(validation_folds[i]['target'], y_pred)\n",
    "            total_score += score\n",
    "        \n",
    "        average_score = total_score / len(training_folds)\n",
    "        if average_score > best_score:\n",
    "            best_score = average_score\n",
    "            best_hyperparameters = params\n",
    "    \n",
    "    return best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that we save our models.  In the old days, one just simply pickled (serialized) the model.  Now, however, certain model types have their own save format.  If the model is from sklearn, it can be pickled, if it's xgboost, for example, the newest format to save it in is JSON, but it can also be pickled.  It's a good idea to stay with the most current methods. \n",
    "- you may want to create a new `models/` subdirectory in your repo to stay organized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've identified which model works the best, implement a prediction pipeline to make sure that you haven't leaked any data, and that the model could be easily deployed if desired.\n",
    "- Your pipeline should load the data, process it, load your saved tuned model, and output a set of predictions\n",
    "- Assume that the new data is in the same JSON format as your original data - you can use your original data to check that the pipeline works correctly\n",
    "- Beware that a pipeline can only handle functions with fit and transform methods.\n",
    "- Classes can be used to get around this, but now sklearn has a wrapper for user defined functions.\n",
    "- You can develop your functions or classes in the notebook here, but once they are working, you should import them from `functions_variables.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [212.00002   180.36714    71.57536   212.00002   212.00002    65.34403\n",
      "   1.3224132 212.00002   212.00002    70.40838    97.386375  212.00002\n",
      "  81.24224   212.00002   193.81508   126.91804   197.62462   152.95367\n",
      " 114.56613    89.24013   212.00002   212.00002    70.418      77.850006\n",
      " 188.31549   212.00002   212.00002   212.00002    18.489634  145.49324\n",
      " 206.45055    97.386375  212.00002   212.00002   113.503174  212.00002\n",
      "  75.236916   66.16294   212.00002   146.76859   212.00002    20.853241\n",
      "  48.267757  152.3542    212.00002   212.00002   147.29456   212.00002\n",
      "  54.761047  108.09569   170.12332   212.00002   212.00002   137.88205\n",
      " 212.00002    72.54093   212.00002    25.33888    69.501595  143.73445\n",
      " 212.00002   212.00002   108.70021    43.695885  167.22116   212.00002\n",
      " 100.70514   179.41112   132.59624    76.211525  212.00002    83.66373\n",
      " 212.00002    82.570465   49.23465    84.368835  212.00002   212.00002\n",
      " 212.00002   212.00002   152.95367   212.00002   212.00002   131.02989\n",
      " 212.00002   108.70021   155.07817   212.00002    60.22296   212.00002\n",
      " 212.00002   180.98315    39.260952  212.00002   212.00002   212.00002\n",
      "  20.46662   212.00002   173.34251    39.260952  212.00002   125.345345\n",
      " 212.00002   212.00002   109.55907    99.5489    212.00002   212.00002\n",
      "  10.806018  192.5757    212.00002    12.655981  175.44006   203.74658\n",
      "  25.33888   212.00002   212.00002   212.00002   152.95367    94.13977\n",
      "  32.6847    118.02955   121.10121    83.66373   158.25815   212.00002\n",
      " 212.00002    75.11885   143.17859    91.57938   212.00002   191.73555\n",
      "  12.663644   39.260952  125.20275     2.6993916  35.500313  212.00002\n",
      " 212.00002   212.00002   212.00002   106.686     212.00002   113.6755\n",
      " 212.00002    18.489634  212.00002   212.00002   212.00002   212.00002\n",
      " 212.00002   212.00002   212.00002   212.00002   212.00002   212.00002\n",
      " 212.00002    75.56436    31.07278   212.00002   128.0003    114.56613\n",
      " 212.00002    91.57938   212.00002   212.00002   212.00002   212.00002\n",
      " 212.00002   184.92766    39.260952  212.00002   168.53534    48.267757\n",
      " 212.00002   212.00002   152.3542     39.353737   46.497334  100.3934\n",
      " 212.00002   100.11393   212.00002   212.00002   212.00002   212.00002\n",
      "  86.39363   179.82861   212.00002    66.16294    13.360692  201.62653\n",
      " 117.41545   164.61678    62.456856  212.00002   212.00002   153.6784\n",
      " 212.00002   173.6243    212.00002   192.94733   212.00002    97.98252\n",
      "  32.6847    151.83472   212.00002   212.00002   116.9424    212.00002\n",
      " 170.64337   212.00002   212.00002    37.48706   212.00002   212.00002\n",
      " 212.00002   212.00002   136.58624   212.00002    75.236916  153.6784\n",
      " 212.00002   212.00002    94.520805    6.904362   53.153942  212.00002\n",
      " 212.00002   113.6755    212.00002   212.00002   212.00002   212.00002\n",
      "  12.655981  212.00002    91.33199   164.25476   212.00002   212.00002\n",
      " 112.13032   212.00002    20.85808     9.424552   61.887722   62.038906\n",
      "  91.33199    83.66373   212.00002   212.00002   125.11753   116.9424\n",
      "  77.850006   48.558193  212.00002   212.00002    75.56436   212.00002\n",
      "  83.20122   118.25002   212.00002   199.86707    43.695885   66.70043\n",
      " 212.00002   212.00002   212.00002    91.57938   167.22116   107.62214\n",
      " 212.00002     2.3945956 112.13032    76.211525  212.00002   195.8225\n",
      "  15.072306  191.73555   117.9293    212.00002   212.00002   178.54915\n",
      " 212.00002   140.66582    57.474773  212.00002   212.00002   212.00002\n",
      " 212.00002     4.030016  212.00002    94.520805   97.713776   93.04709\n",
      " 212.00002    80.76651    33.48837    20.85808   212.00002    35.500313\n",
      " 212.00002   173.34251   115.81643   212.00002   212.00002   212.00002\n",
      "  69.501595  212.00002   173.6243     61.908398  212.00002   187.89073\n",
      "  25.117603   65.178154  212.00002   108.09569   212.00002   212.00002\n",
      " 150.79654   212.00002   212.00002    84.368835  148.74954    20.46662\n",
      " 212.00002   212.00002   212.00002   212.00002    71.57536   212.00002\n",
      "  87.06202   212.00002    86.39363   212.00002   212.00002   212.00002\n",
      "   3.3688576 212.00002   212.00002    26.504585  212.00002   158.25815\n",
      " 212.00002    78.72487   212.00002   212.00002   100.3934    212.00002\n",
      " 117.69644   212.00002   212.00002   212.00002   212.00002     5.1950912\n",
      " 212.00002   212.00002   125.065315   10.029841  148.16812    10.977195\n",
      "  93.127426  212.00002   212.00002   212.00002   212.00002   212.00002\n",
      "  73.619804  146.76859    50.529884  212.00002    73.619804  212.00002\n",
      " 186.15755   212.00002   111.132706  212.00002   180.70265    68.3\n",
      " 202.59395   212.00002   212.00002    96.7028    212.00002   189.89629\n",
      " 212.00002   156.40744   212.00002   180.70265    97.22153   123.63634\n",
      " 212.00002    42.421818  156.40744   132.59624    23.384144  114.43999\n",
      "  46.497334  212.00002    76.82039     8.085263   46.64681    84.368835\n",
      " 210.6162    180.70265    17.652798   93.56842   212.00002    44.79252\n",
      "  20.853241   48.558193  140.4133    212.00002   212.00002   212.00002\n",
      "  28.88051   212.00002   164.61678    41.407104  182.8977    212.00002\n",
      " 212.00002    22.177858   29.350004  212.00002   171.78229   212.00002\n",
      " 212.00002   133.59811   179.41112   212.00002   212.00002    69.16697\n",
      " 212.00002   212.00002   186.59312    97.98252   184.92766   155.99557\n",
      "  62.456856  212.00002   212.00002    61.207466  212.00002    80.220024\n",
      " 212.00002   212.00002   212.00002   212.00002   212.00002   136.58624\n",
      " 160.13434   212.00002   144.69408   212.00002    99.5489    212.00002\n",
      "  12.344089   66.70043    91.26996   212.00002   212.00002   212.00002\n",
      "  67.467255  212.00002   212.00002    93.56842   212.00002    18.489634\n",
      "  37.48706   212.00002   212.00002   125.20275   156.27371   212.00002\n",
      "  46.64681   156.27371   136.85953    57.474773   13.360692  212.00002\n",
      "  98.59168    81.24224   212.00002   212.00002    32.00344   212.00002\n",
      " 212.00002    44.79252   212.00002   111.132706  168.89671   212.00002\n",
      " 212.00002    58.410492   32.00344   212.00002   212.00002   115.81643\n",
      " 171.78229   118.64189    71.57536   212.00002   100.70514   177.25412\n",
      " 212.00002   212.00002   156.40744   212.00002    13.3197155 103.62134\n",
      " 212.00002   180.70265    45.814426   26.504585   42.421818  178.54915\n",
      "  97.713776  197.62462   212.00002   212.00002   186.15755   113.6755\n",
      "  25.33888    68.46815  ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Custom transformer function for loading and preprocessing data\n",
    "\n",
    "def load_and_preprocess_data(data_path):\n",
    "    # Load CSV data\n",
    "\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "# Function to make predictions using the loaded model\n",
    "\n",
    "def predict_with_model(X, model_path):\n",
    "    # Load the saved model\n",
    "\n",
    "    model = XGBRegressor()\n",
    "    model.load_model(model_path)\n",
    "    return model.predict(X)\n",
    "\n",
    "# Get the parent directory of the current working directory\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# Construct the full path to the CSV file\n",
    "\n",
    "data_path = os.path.join(parent_dir, 'data', 'processed', 'x_test.csv')\n",
    "\n",
    "# Construct the full path to the XGBoost model file\n",
    "\n",
    "model_path = os.path.join(parent_dir, 'models', 'xgboost_model.model')\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('load_and_preprocess', FunctionTransformer(load_and_preprocess_data)),\n",
    "    ('predict', FunctionTransformer(predict_with_model, kw_args={'model_path': model_path}))\n",
    "])\n",
    "\n",
    "# Test the pipeline with original data\n",
    "\n",
    "try:\n",
    "    predictions = pipeline.transform(data_path)\n",
    "    print(\"Predictions:\", predictions)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines come from sklearn.  When a pipeline is pickled, all of the information in the pipeline is stored with it.  For example, if we were deploying a model, and we had fit a scaler on the training data, we would want the same, already fitted scaling object to transform the new data with.  This is all stored when the pipeline is pickled.\n",
    "- save your final pipeline in your `models/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your pipeline here\n",
    "\n",
    "import pickle\n",
    "\n",
    "pipeline_path = '../models/pipeline.pkl'\n",
    "\n",
    "# Save the pipeline\n",
    "\n",
    "with open(pipeline_path, 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
