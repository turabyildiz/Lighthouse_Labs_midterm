{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The os module has a perfect method to list files in a directory.\n",
    "- Pandas json normalize could work here but is not necessary to convert the JSON data to a dataframe.\n",
    "- You may need a nested for-loop to access each sale!\n",
    "- We've put a lot of time into creating the structure of this repository, and it's a good example for future projects.  In the file functions_variables.py, there is an example function that you can import and use.  If you have any variables, functions or classes that you want to make, they can be put in the functions_variables.py file and imported into a notebook.  Note that only .py files can be imported into a notebook. If you want to import everything from a .py file, you can use the following:\n",
    "```python\n",
    "from functions_variables import *\n",
    "```\n",
    "If you just import functions_variables, then each object from the file will need to be prepended with \"functions_variables\"\\\n",
    "Using this .py file will keep your notebooks very organized and make it easier to reuse code between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (this is not an exhaustive list of libraries)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from functions_variables import encode_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".gitkeep\n",
      "AK_Juneau_0.json\n",
      "AK_Juneau_1.json\n",
      "AK_Juneau_2.json\n",
      "AK_Juneau_3.json\n",
      "AK_Juneau_4.json\n",
      "AL_Montgomery_0.json\n",
      "AL_Montgomery_1.json\n",
      "AL_Montgomery_2.json\n",
      "AL_Montgomery_3.json\n",
      "AL_Montgomery_4.json\n",
      "AR_LittleRock_0.json\n",
      "AR_LittleRock_1.json\n",
      "AR_LittleRock_2.json\n",
      "AR_LittleRock_3.json\n",
      "AR_LittleRock_4.json\n",
      "AZ_Phoenix_0.json\n",
      "AZ_Phoenix_1.json\n",
      "AZ_Phoenix_2.json\n",
      "AZ_Phoenix_3.json\n",
      "AZ_Phoenix_4.json\n",
      "CA_Sacramento_0.json\n",
      "CA_Sacramento_1.json\n",
      "CA_Sacramento_2.json\n",
      "CA_Sacramento_3.json\n",
      "CA_Sacramento_4.json\n",
      "CO_Denver_0.json\n",
      "CO_Denver_1.json\n",
      "CO_Denver_2.json\n",
      "CO_Denver_3.json\n",
      "CO_Denver_4.json\n",
      "CT_Hartford_0.json\n",
      "CT_Hartford_1.json\n",
      "CT_Hartford_2.json\n",
      "CT_Hartford_3.json\n",
      "CT_Hartford_4.json\n",
      "DE_Dover_0.json\n",
      "DE_Dover_1.json\n",
      "DE_Dover_2.json\n",
      "DE_Dover_3.json\n",
      "DE_Dover_4.json\n",
      "FL_Tallahassee_0.json\n",
      "FL_Tallahassee_1.json\n",
      "FL_Tallahassee_2.json\n",
      "FL_Tallahassee_3.json\n",
      "FL_Tallahassee_4.json\n",
      "GA_Atlanta_0.json\n",
      "GA_Atlanta_1.json\n",
      "GA_Atlanta_2.json\n",
      "GA_Atlanta_3.json\n",
      "GA_Atlanta_4.json\n",
      "HI_Honolulu_0.json\n",
      "HI_Honolulu_1.json\n",
      "HI_Honolulu_2.json\n",
      "HI_Honolulu_3.json\n",
      "HI_Honolulu_4.json\n",
      "IA_DesMoines_0.json\n",
      "IA_DesMoines_1.json\n",
      "IA_DesMoines_2.json\n",
      "IA_DesMoines_3.json\n",
      "IA_DesMoines_4.json\n",
      "ID_Boise_0.json\n",
      "ID_Boise_1.json\n",
      "ID_Boise_2.json\n",
      "ID_Boise_3.json\n",
      "ID_Boise_4.json\n",
      "IL_Springfield_0.json\n",
      "IL_Springfield_1.json\n",
      "IL_Springfield_2.json\n",
      "IL_Springfield_3.json\n",
      "IL_Springfield_4.json\n",
      "IN_Indianapolis_0.json\n",
      "IN_Indianapolis_1.json\n",
      "IN_Indianapolis_2.json\n",
      "IN_Indianapolis_3.json\n",
      "IN_Indianapolis_4.json\n",
      "KS_Topeka_0.json\n",
      "KS_Topeka_1.json\n",
      "KS_Topeka_2.json\n",
      "KS_Topeka_3.json\n",
      "KS_Topeka_4.json\n",
      "KY_Frankfort_0.json\n",
      "KY_Frankfort_1.json\n",
      "KY_Frankfort_2.json\n",
      "KY_Frankfort_3.json\n",
      "KY_Frankfort_4.json\n",
      "LA_BatonRouge_0.json\n",
      "LA_BatonRouge_1.json\n",
      "LA_BatonRouge_2.json\n",
      "LA_BatonRouge_3.json\n",
      "LA_BatonRouge_4.json\n",
      "MA_Boston_0.json\n",
      "MA_Boston_1.json\n",
      "MA_Boston_2.json\n",
      "MA_Boston_3.json\n",
      "MA_Boston_4.json\n",
      "MD_Annapolis_0.json\n",
      "MD_Annapolis_1.json\n",
      "MD_Annapolis_2.json\n",
      "MD_Annapolis_3.json\n",
      "MD_Annapolis_4.json\n",
      "ME_Augusta_0.json\n",
      "ME_Augusta_1.json\n",
      "ME_Augusta_2.json\n",
      "ME_Augusta_3.json\n",
      "ME_Augusta_4.json\n",
      "MI_Lansing_0.json\n",
      "MI_Lansing_1.json\n",
      "MI_Lansing_2.json\n",
      "MI_Lansing_3.json\n",
      "MI_Lansing_4.json\n",
      "MN_St.Paul_0.json\n",
      "MN_St.Paul_1.json\n",
      "MN_St.Paul_2.json\n",
      "MN_St.Paul_3.json\n",
      "MN_St.Paul_4.json\n",
      "MO_JeffersonCity_0.json\n",
      "MO_JeffersonCity_1.json\n",
      "MO_JeffersonCity_2.json\n",
      "MO_JeffersonCity_3.json\n",
      "MO_JeffersonCity_4.json\n",
      "MS_Jackson_0.json\n",
      "MS_Jackson_1.json\n",
      "MS_Jackson_2.json\n",
      "MS_Jackson_3.json\n",
      "MS_Jackson_4.json\n",
      "MT_Helena_0.json\n",
      "MT_Helena_1.json\n",
      "MT_Helena_2.json\n",
      "MT_Helena_3.json\n",
      "MT_Helena_4.json\n",
      "NC_Raleigh_0.json\n",
      "NC_Raleigh_1.json\n",
      "NC_Raleigh_2.json\n",
      "NC_Raleigh_3.json\n",
      "NC_Raleigh_4.json\n",
      "ND_Bismarck_0.json\n",
      "ND_Bismarck_1.json\n",
      "ND_Bismarck_2.json\n",
      "ND_Bismarck_3.json\n",
      "ND_Bismarck_4.json\n",
      "NE_Lincoln_0.json\n",
      "NE_Lincoln_1.json\n",
      "NE_Lincoln_2.json\n",
      "NE_Lincoln_3.json\n",
      "NE_Lincoln_4.json\n",
      "NH_Concord_0.json\n",
      "NH_Concord_1.json\n",
      "NH_Concord_2.json\n",
      "NH_Concord_3.json\n",
      "NH_Concord_4.json\n",
      "NJ_Trenton_0.json\n",
      "NJ_Trenton_1.json\n",
      "NJ_Trenton_2.json\n",
      "NJ_Trenton_3.json\n",
      "NJ_Trenton_4.json\n",
      "NM_SantaFe_0.json\n",
      "NM_SantaFe_1.json\n",
      "NM_SantaFe_2.json\n",
      "NM_SantaFe_3.json\n",
      "NM_SantaFe_4.json\n",
      "NV_CarsonCity_0.json\n",
      "NV_CarsonCity_1.json\n",
      "NV_CarsonCity_2.json\n",
      "NV_CarsonCity_3.json\n",
      "NV_CarsonCity_4.json\n",
      "NY_Albany_0.json\n",
      "NY_Albany_1.json\n",
      "NY_Albany_2.json\n",
      "NY_Albany_3.json\n",
      "NY_Albany_4.json\n",
      "OH_Columbus_0.json\n",
      "OH_Columbus_1.json\n",
      "OH_Columbus_2.json\n",
      "OH_Columbus_3.json\n",
      "OH_Columbus_4.json\n",
      "OK_OklahomaCity_0.json\n",
      "OK_OklahomaCity_1.json\n",
      "OK_OklahomaCity_2.json\n",
      "OK_OklahomaCity_3.json\n",
      "OK_OklahomaCity_4.json\n",
      "OR_Salem_0.json\n",
      "OR_Salem_1.json\n",
      "OR_Salem_2.json\n",
      "OR_Salem_3.json\n",
      "OR_Salem_4.json\n",
      "PA_Harrisburg_0.json\n",
      "PA_Harrisburg_1.json\n",
      "PA_Harrisburg_2.json\n",
      "PA_Harrisburg_3.json\n",
      "PA_Harrisburg_4.json\n",
      "processed\n",
      "RI_Providence_0.json\n",
      "RI_Providence_1.json\n",
      "RI_Providence_2.json\n",
      "RI_Providence_3.json\n",
      "RI_Providence_4.json\n",
      "SC_Columbia_0.json\n",
      "SC_Columbia_1.json\n",
      "SC_Columbia_2.json\n",
      "SC_Columbia_3.json\n",
      "SC_Columbia_4.json\n",
      "SD_Pierre_0.json\n",
      "SD_Pierre_1.json\n",
      "SD_Pierre_2.json\n",
      "SD_Pierre_3.json\n",
      "SD_Pierre_4.json\n",
      "TN_Nashville_0.json\n",
      "TN_Nashville_1.json\n",
      "TN_Nashville_2.json\n",
      "TN_Nashville_3.json\n",
      "TN_Nashville_4.json\n",
      "TX_Austin_0.json\n",
      "TX_Austin_1.json\n",
      "TX_Austin_2.json\n",
      "TX_Austin_3.json\n",
      "TX_Austin_4.json\n",
      "UT_SaltLakeCity_0.json\n",
      "UT_SaltLakeCity_1.json\n",
      "UT_SaltLakeCity_2.json\n",
      "UT_SaltLakeCity_3.json\n",
      "UT_SaltLakeCity_4.json\n",
      "VA_Richmond_0.json\n",
      "VA_Richmond_1.json\n",
      "VA_Richmond_2.json\n",
      "VA_Richmond_3.json\n",
      "VA_Richmond_4.json\n",
      "VT_Montpelier_0.json\n",
      "VT_Montpelier_1.json\n",
      "VT_Montpelier_2.json\n",
      "VT_Montpelier_3.json\n",
      "VT_Montpelier_4.json\n",
      "WA_Olympia_0.json\n",
      "WA_Olympia_1.json\n",
      "WA_Olympia_2.json\n",
      "WA_Olympia_3.json\n",
      "WA_Olympia_4.json\n",
      "WI_Madison_0.json\n",
      "WI_Madison_1.json\n",
      "WI_Madison_2.json\n",
      "WI_Madison_3.json\n",
      "WI_Madison_4.json\n",
      "WV_Charleston_0.json\n",
      "WV_Charleston_1.json\n",
      "WV_Charleston_2.json\n",
      "WV_Charleston_3.json\n",
      "WV_Charleston_4.json\n",
      "WY_Cheyenne_0.json\n",
      "WY_Cheyenne_1.json\n",
      "WY_Cheyenne_2.json\n",
      "WY_Cheyenne_3.json\n",
      "WY_Cheyenne_4.json\n"
     ]
    }
   ],
   "source": [
    "# load one file first to see what type of data you're dealing with and what attributes it has\n",
    "\n",
    "directory = r\"C:\\Users\\turab\\data-project-midterm\\data\"\n",
    "\n",
    "# Use os.listdir to get files\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Print all files\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all sales into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\2437266733.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       last_update_date                                               tags  \\\n",
      "0  2023-09-19T20:52:50Z  [carport, community_outdoor_space, cul_de_sac,...   \n",
      "1                  None                                               None   \n",
      "2                  None                                               None   \n",
      "3                  None                                               None   \n",
      "4                  None                                               None   \n",
      "\n",
      "                                           permalink status  \\\n",
      "0       9453-Herbert-Pl_Juneau_AK_99801_M90744-30767   sold   \n",
      "1  8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...   sold   \n",
      "2      4515-Glacier-Hwy_Juneau_AK_99801_M94790-68516   sold   \n",
      "3  17850-Point-Stephens-Rd_Juneau_AK_99801_M98793...   sold   \n",
      "4  9951-Stephen-Richards-Memorial-Dr_Juneau_AK_99...   sold   \n",
      "\n",
      "                     list_date open_houses  \\\n",
      "0  2023-06-29T21:16:25.000000Z        None   \n",
      "1                         None        None   \n",
      "2                         None        None   \n",
      "3                         None        None   \n",
      "4                         None        None   \n",
      "\n",
      "                                            branding  list_price property_id  \\\n",
      "0  [{'name': 'EXP Realty LLC - Southeast Alaska',...    554950.0  9074430767   \n",
      "1  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9424983842   \n",
      "2  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9479068516   \n",
      "3  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9879331943   \n",
      "4  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9521639574   \n",
      "\n",
      "                                              photos  ...  \\\n",
      "0  [{'tags': [{'label': 'house_view', 'probabilit...  ...   \n",
      "1                                               None  ...   \n",
      "2                                               None  ...   \n",
      "3                                               None  ...   \n",
      "4                                               None  ...   \n",
      "\n",
      "  location.county.fips_code location.county.name primary_photo  source  \\\n",
      "0                      None               Juneau           NaN     NaN   \n",
      "1                      None               Juneau           NaN     NaN   \n",
      "2                      None               Juneau           NaN     NaN   \n",
      "3                      None               Juneau           NaN     NaN   \n",
      "4                      None               Juneau           NaN     NaN   \n",
      "\n",
      "  products location.address.coordinate other_listings community.advertisers  \\\n",
      "0      NaN                         NaN            NaN                   NaN   \n",
      "1      NaN                         NaN            NaN                   NaN   \n",
      "2      NaN                         NaN            NaN                   NaN   \n",
      "3      NaN                         NaN            NaN                   NaN   \n",
      "4      NaN                         NaN            NaN                   NaN   \n",
      "\n",
      "  community.description.name location.county  \n",
      "0                        NaN             NaN  \n",
      "1                        NaN             NaN  \n",
      "2                        NaN             NaN  \n",
      "3                        NaN             NaN  \n",
      "4                        NaN             NaN  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_and_combine_json_files(directory):\n",
    "    data_frames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                json_data = json.load(file)\n",
    "                \n",
    "                # Normalize the JSON structure to a flat table\n",
    "                if 'data' in json_data and 'results' in json_data['data']:\n",
    "                    df = json_normalize(json_data['data']['results'])\n",
    "                    data_frames.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames into one\n",
    "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "directory = r\"C:\\Users\\turab\\data-project-midterm\\data\"  # Update this path\n",
    "\n",
    "# Load and combine the JSON files\n",
    "combined_data = load_and_combine_json_files(directory)\n",
    "\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, ensure that you have all sales in a dataframe.\n",
    "- Is each cell one value, or do some cells have lists?\n",
    "- Maybe the \"tags\" will help create some features.\n",
    "- What are the data types of each column?\n",
    "- Some sales may not actually include the sale price.  These rows should be dropped.\n",
    "- Some sales don't include the property type.\n",
    "- There are a lot of None values.  Should these be dropped or replaced with something?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop or replace values as neccesary \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_for_lists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check if some columns have lists\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m list_columns_combined_data \u001b[38;5;241m=\u001b[39m check_for_lists(combined_data)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(list_columns_combined_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_for_lists' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if some columns have lists\n",
    "\n",
    "list_columns_combined_data = check_for_lists(combined_data)\n",
    "print(list_columns_combined_data)\n",
    "\n",
    "# Tags, branding, photos, virtual tours, source agents, other listings, etc have lists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tags:\n",
      "large_porch\n",
      "community_swimming_pool\n",
      "garage_3_or_more\n",
      "waterfront\n",
      "golf_course_lot_or_frontage\n",
      "golf_course_view\n",
      "kitchen_island\n",
      "clubhouse\n",
      "private_backyard\n",
      "wrap_around_porch\n",
      "washer_dryer\n",
      "dining_room\n",
      "beautiful_backyard\n",
      "central_air\n",
      "rental_property\n",
      "well_water\n",
      "community_park\n",
      "community_golf\n",
      "view\n",
      "granite_kitchen\n",
      "central_heat\n",
      "water_view\n",
      "recreation_facilities\n",
      "community_horse_facilities\n",
      "courtyard_entry\n",
      "greenbelt\n",
      "indoor_basketball_court\n",
      "big_lot\n",
      "pond\n",
      "investment_opportunity\n",
      "golf_course\n",
      "smart_homes\n",
      "security\n",
      "community_gym\n",
      "views\n",
      "river_view\n",
      "wine_cellar\n",
      "family_room\n",
      "ensuite\n",
      "gated_community\n",
      "rv_or_boat_parking\n",
      "single_story\n",
      "library\n",
      "private_bathroom\n",
      "no_hoa\n",
      "cathedral_ceiling\n",
      "carport\n",
      "community_elevator\n",
      "den_or_office\n",
      "tennis_court\n",
      "lake_view\n",
      "swimming_pool\n",
      "coffer_ceiling\n",
      "modern_kitchen\n",
      "community_spa_or_hot_tub\n",
      "trails\n",
      "outdoor_kitchen\n",
      "community_boat_facilities\n",
      "two_kitchen\n",
      "community_outdoor_space\n",
      "exposed_brick\n",
      "pets_allowed\n",
      "playground\n",
      "master_suite\n",
      "community_center\n",
      "big_bathroom\n",
      "mountain_view\n",
      "horse_property\n",
      "city_view\n",
      "fireplace\n",
      "fenced_yard\n",
      "park\n",
      "jack_and_jill_bathroom\n",
      "vaulted_ceiling\n",
      "guest_house\n",
      "ranch\n",
      "fruit_trees\n",
      "open_floor_plan\n",
      "lake\n",
      "two_or_more_stories\n",
      "corner_lot\n",
      "hardwood_floors\n",
      "floor_plan\n",
      "disability_features\n",
      "private_courtyard\n",
      "hoa\n",
      "marina\n",
      "media_room\n",
      "fenced_courtyard\n",
      "basement\n",
      "handicap_access\n",
      "two_master_suites\n",
      "maintenance\n",
      "big_yard\n",
      "garage_2_or_more\n",
      "volleyball\n",
      "dual_master_bedroom\n",
      "outbuilding\n",
      "detached_guest_house\n",
      "furniture\n",
      "ocean_view\n",
      "energy_efficient\n",
      "equestrian\n",
      "fixer_upper\n",
      "rv_parking\n",
      "wooded_land\n",
      "efficient\n",
      "storm_shelter\n",
      "new_roof\n",
      "forced_air\n",
      "groundscare\n",
      "solar_panels\n",
      "river_access\n",
      "horse_facilities\n",
      "cul_de_sac\n",
      "high_ceiling\n",
      "shopping\n",
      "game_room\n",
      "horse_stables\n",
      "medicalcare\n",
      "basketball_court\n",
      "private_parking\n",
      "farm\n",
      "spa_or_hot_tub\n",
      "solar_system\n",
      "baseball\n",
      "gourmet_kitchen\n",
      "open_house\n",
      "laundry_room\n",
      "screen_porch\n",
      "boat_dock\n",
      "dishwasher\n",
      "beach\n",
      "theater_room\n",
      "basketball\n",
      "hill_or_mountain_view\n",
      "master_bedroom\n",
      "community_clubhouse\n",
      "community_security_features\n",
      "first_floor_master_bedroom\n",
      "open_kitchen\n",
      "updated_kitchen\n",
      "soccer\n",
      "tennis\n",
      "master_bathroom\n",
      "community_tennis_court\n",
      "front_porch\n",
      "garage_1_or_more\n",
      "low_hoa\n",
      "greenhouse\n",
      "senior_community\n",
      "white_kitchen\n",
      "guest_parking\n",
      "large_kitchen\n",
      "elevator\n"
     ]
    }
   ],
   "source": [
    "# Display all from tags column \n",
    "\n",
    "if 'tags' in combined_data.columns:\n",
    "    # Initialize an empty set to store unique tags\n",
    "    unique_tags = set()\n",
    "    \n",
    "    # Iterate over each entry in the 'tags' column\n",
    "    for tag_list in combined_data['tags']:\n",
    "        if isinstance(tag_list, list):  # Ensure the entry is a list\n",
    "            unique_tags.update(tag_list)  # Add tags to the set, avoiding duplicates\n",
    "    \n",
    "    # Print the unique set of tags\n",
    "    print(\"Unique tags:\")\n",
    "    for tag in unique_tags:\n",
    "        print(tag)\n",
    "else:\n",
    "    print(\"'tags' column does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      "[dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('float64'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('float64'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('float64'), dtype('float64'), dtype('O'), dtype('float64'), dtype('float64'), dtype('O'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('O'), dtype('O'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('float64'), dtype('float64'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "# Data types of each column\n",
    "\n",
    "data_types_list = combined_data.dtypes.tolist()\n",
    "\n",
    "print(\"Data types of each column:\")\n",
    "print(data_types_list)\n",
    "\n",
    "# There are objects, float64's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame after dropping rows with missing sales price: (7721, 67)\n"
     ]
    }
   ],
   "source": [
    "# drop sales that dont include sales price\n",
    "\n",
    "combined_data = combined_data.dropna(subset=['list_price'])\n",
    "\n",
    "# Print the shape of the DataFrame to verify the number of rows after dropping\n",
    "\n",
    "print(\"Shape of DataFrame after dropping rows with missing sales price:\", combined_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       None\n",
      "1       None\n",
      "2       None\n",
      "3       None\n",
      "4       None\n",
      "        ... \n",
      "8186     NaN\n",
      "8187     NaN\n",
      "8188     NaN\n",
      "8189     NaN\n",
      "8190     NaN\n",
      "Name: description.sub_type, Length: 8191, dtype: object\n",
      "Shape of DataFrame after dropping rows with missing property type: (1427, 67)\n"
     ]
    }
   ],
   "source": [
    "# Drop sales that dont have a property type\n",
    "\n",
    "# Display the property type column\n",
    "\n",
    "print(combined_data['description.sub_type'])\n",
    "\n",
    "# Drop N/A's\n",
    "\n",
    "combined_data = combined_data.dropna(subset=['description.sub_type'])\n",
    "\n",
    "# Print the shape of the DataFrame to verify the number of rows after dropping\n",
    "\n",
    "print(\"Shape of DataFrame after dropping rows with missing property type:\", combined_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the fact that with tags, there are a lot of categorical variables.\n",
    "- How many columns would we have if we OHE tags, city and state?\n",
    "- Perhaps we can get rid of tags that have a low frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          last_update_date                                               tags  \\\n",
      "5     2023-08-04T22:49:14Z  [carport, hill_or_mountain_view, ocean_view, s...   \n",
      "12    2023-08-04T22:49:14Z  [carport, hill_or_mountain_view, ocean_view, s...   \n",
      "18    2023-08-04T22:49:14Z  [carport, hill_or_mountain_view, ocean_view, s...   \n",
      "23    2023-08-04T22:49:14Z  [carport, hill_or_mountain_view, ocean_view, s...   \n",
      "27    2023-08-04T22:49:14Z  [carport, hill_or_mountain_view, ocean_view, s...   \n",
      "...                    ...                                                ...   \n",
      "7971  2024-01-03T19:35:24Z  [central_air, community_elevator, community_ou...   \n",
      "7972  2024-01-03T19:41:48Z  [community_outdoor_space, disability_features,...   \n",
      "7976  2024-01-03T02:46:30Z  [central_air, community_elevator, community_gy...   \n",
      "7977  2024-01-10T18:23:43Z  [central_air, community_clubhouse, community_o...   \n",
      "7978  2023-12-29T18:36:39Z  [central_air, community_elevator, community_gy...   \n",
      "\n",
      "                                              permalink status  \\\n",
      "5     11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   sold   \n",
      "12    11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   sold   \n",
      "18    11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   sold   \n",
      "23    11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   sold   \n",
      "27    11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   sold   \n",
      "...                                                 ...    ...   \n",
      "7971  3848-Maple-Grove-Dr-Apt-107_Madison_WI_53719_M...   sold   \n",
      "7972        7049-Watts-Rd_Madison_WI_53719_M81629-27916   sold   \n",
      "7976  123-N-Blount-St-Unit-306_Madison_WI_53703_M852...   sold   \n",
      "7977  49-Golf-Course-Rd-Unit-H_Madison_WI_53704_M898...   sold   \n",
      "7978  333-W-Mifflin-St-Unit-1258_Madison_WI_53703_M8...   sold   \n",
      "\n",
      "                        list_date open_houses  \\\n",
      "5     2023-08-21T21:01:22.000000Z        None   \n",
      "12    2023-08-21T21:01:22.000000Z        None   \n",
      "18    2023-08-21T21:01:22.000000Z        None   \n",
      "23    2023-08-21T21:01:22.000000Z        None   \n",
      "27    2023-08-21T21:01:22.000000Z        None   \n",
      "...                           ...         ...   \n",
      "7971  2023-11-07T14:56:36.000000Z        None   \n",
      "7972  2023-12-14T15:47:56.000000Z        None   \n",
      "7976  2023-09-28T04:12:23.000000Z        None   \n",
      "7977  2023-10-13T13:09:28.000000Z        None   \n",
      "7978  2023-09-28T13:48:42.000000Z        None   \n",
      "\n",
      "                                               branding  list_price  \\\n",
      "5     [{'name': 'Platinum Keller Williams Realty Ala...    415000.0   \n",
      "12    [{'name': 'Platinum Keller Williams Realty Ala...    415000.0   \n",
      "18    [{'name': 'Platinum Keller Williams Realty Ala...    415000.0   \n",
      "23    [{'name': 'Platinum Keller Williams Realty Ala...    415000.0   \n",
      "27    [{'name': 'Platinum Keller Williams Realty Ala...    415000.0   \n",
      "...                                                 ...         ...   \n",
      "7971  [{'name': 'Restaino & Associates ERA Powered',...    250000.0   \n",
      "7972  [{'name': 'STARK COMPANY REALTORS', 'photo': N...    150000.0   \n",
      "7976  [{'name': 'THE KRUSE COMPANY REALTORS', 'photo...    435000.0   \n",
      "7977  [{'name': 'Stark Company, REALTORS', 'photo': ...    239500.0   \n",
      "7978  [{'name': 'Sprinkman Real Estate', 'photo': No...    770000.0   \n",
      "\n",
      "     property_id                                             photos  ...  \\\n",
      "5     7412309719                                               None  ...   \n",
      "12    7412309719                                               None  ...   \n",
      "18    7412309719                                               None  ...   \n",
      "23    7412309719                                               None  ...   \n",
      "27    7412309719                                               None  ...   \n",
      "...          ...                                                ...  ...   \n",
      "7971  8244577290  [{'tags': [{'label': 'house_view', 'probabilit...  ...   \n",
      "7972  8162927916  [{'tags': [{'label': 'house_view', 'probabilit...  ...   \n",
      "7976  8529464413  [{'tags': [{'label': 'house_view', 'probabilit...  ...   \n",
      "7977  8983959666  [{'tags': [{'label': 'house_view', 'probabilit...  ...   \n",
      "7978  8616401242  [{'tags': [{'label': 'bedroom', 'probability':...  ...   \n",
      "\n",
      "     location.address.state_Ohio location.address.state_Oklahoma  \\\n",
      "5                          False                           False   \n",
      "12                         False                           False   \n",
      "18                         False                           False   \n",
      "23                         False                           False   \n",
      "27                         False                           False   \n",
      "...                          ...                             ...   \n",
      "7971                       False                           False   \n",
      "7972                       False                           False   \n",
      "7976                       False                           False   \n",
      "7977                       False                           False   \n",
      "7978                       False                           False   \n",
      "\n",
      "     location.address.state_Pennsylvania  location.address.state_Rhode Island  \\\n",
      "5                                  False                                False   \n",
      "12                                 False                                False   \n",
      "18                                 False                                False   \n",
      "23                                 False                                False   \n",
      "27                                 False                                False   \n",
      "...                                  ...                                  ...   \n",
      "7971                               False                                False   \n",
      "7972                               False                                False   \n",
      "7976                               False                                False   \n",
      "7977                               False                                False   \n",
      "7978                               False                                False   \n",
      "\n",
      "     location.address.state_South Carolina location.address.state_Texas  \\\n",
      "5                                    False                        False   \n",
      "12                                   False                        False   \n",
      "18                                   False                        False   \n",
      "23                                   False                        False   \n",
      "27                                   False                        False   \n",
      "...                                    ...                          ...   \n",
      "7971                                 False                        False   \n",
      "7972                                 False                        False   \n",
      "7976                                 False                        False   \n",
      "7977                                 False                        False   \n",
      "7978                                 False                        False   \n",
      "\n",
      "     location.address.state_Utah location.address.state_Virginia  \\\n",
      "5                          False                           False   \n",
      "12                         False                           False   \n",
      "18                         False                           False   \n",
      "23                         False                           False   \n",
      "27                         False                           False   \n",
      "...                          ...                             ...   \n",
      "7971                       False                           False   \n",
      "7972                       False                           False   \n",
      "7976                       False                           False   \n",
      "7977                       False                           False   \n",
      "7978                       False                           False   \n",
      "\n",
      "     location.address.state_Washington location.address.state_Wisconsin  \n",
      "5                                False                            False  \n",
      "12                               False                            False  \n",
      "18                               False                            False  \n",
      "23                               False                            False  \n",
      "27                               False                            False  \n",
      "...                                ...                              ...  \n",
      "7971                             False                             True  \n",
      "7972                             False                             True  \n",
      "7976                             False                             True  \n",
      "7977                             False                             True  \n",
      "7978                             False                             True  \n",
      "\n",
      "[1427 rows x 148 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>branding</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>community</th>\n",
       "      <th>...</th>\n",
       "      <th>master_bathroom</th>\n",
       "      <th>community_tennis_court</th>\n",
       "      <th>front_porch</th>\n",
       "      <th>garage_1_or_more</th>\n",
       "      <th>low_hoa</th>\n",
       "      <th>senior_community</th>\n",
       "      <th>white_kitchen</th>\n",
       "      <th>guest_parking</th>\n",
       "      <th>large_kitchen</th>\n",
       "      <th>elevator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'Platinum Keller Williams Realty Ala...</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'Platinum Keller Williams Realty Ala...</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'Platinum Keller Williams Realty Ala...</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'Platinum Keller Williams Realty Ala...</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'Platinum Keller Williams Realty Ala...</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        last_update_date                                          permalink  \\\n",
       "5   2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "12  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "18  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "23  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "27  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "\n",
       "   status                    list_date open_houses  \\\n",
       "5    sold  2023-08-21T21:01:22.000000Z        None   \n",
       "12   sold  2023-08-21T21:01:22.000000Z        None   \n",
       "18   sold  2023-08-21T21:01:22.000000Z        None   \n",
       "23   sold  2023-08-21T21:01:22.000000Z        None   \n",
       "27   sold  2023-08-21T21:01:22.000000Z        None   \n",
       "\n",
       "                                             branding  list_price property_id  \\\n",
       "5   [{'name': 'Platinum Keller Williams Realty Ala...    415000.0  7412309719   \n",
       "12  [{'name': 'Platinum Keller Williams Realty Ala...    415000.0  7412309719   \n",
       "18  [{'name': 'Platinum Keller Williams Realty Ala...    415000.0  7412309719   \n",
       "23  [{'name': 'Platinum Keller Williams Realty Ala...    415000.0  7412309719   \n",
       "27  [{'name': 'Platinum Keller Williams Realty Ala...    415000.0  7412309719   \n",
       "\n",
       "   photos community  ... master_bathroom community_tennis_court  front_porch  \\\n",
       "5    None      None  ...             0.0                    0.0          0.0   \n",
       "12   None      None  ...             0.0                    0.0          0.0   \n",
       "18   None      None  ...             0.0                    0.0          0.0   \n",
       "23   None      None  ...             0.0                    0.0          0.0   \n",
       "27   None      None  ...             0.0                    0.0          0.0   \n",
       "\n",
       "   garage_1_or_more low_hoa senior_community white_kitchen guest_parking  \\\n",
       "5               0.0     0.0              0.0           0.0           1.0   \n",
       "12              1.0     0.0              0.0           0.0           0.0   \n",
       "18              1.0     0.0              0.0           0.0           0.0   \n",
       "23              0.0     0.0              0.0           0.0           0.0   \n",
       "27              1.0     0.0              0.0           0.0           0.0   \n",
       "\n",
       "   large_kitchen  elevator  \n",
       "5            0.0       0.0  \n",
       "12           0.0       0.0  \n",
       "18           0.0       0.0  \n",
       "23           0.0       0.0  \n",
       "27           0.0       0.0  \n",
       "\n",
       "[5 rows x 274 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OHE categorical variables here\n",
    "\n",
    "encoded_df = pd.get_dummies(combined_data, columns=['location.address.city', 'location.address.state'])\n",
    "\n",
    "# Display the encoded DataFrame\n",
    "print(encoded_df)\n",
    "\n",
    "# tags will have to be done manually\n",
    "\n",
    "# Let's convert the 'tags' column to a set of unique tags\n",
    "\n",
    "unique_tags = set(tag for tags_list in encoded_df['tags'] if tags_list is not None for tag in tags_list)\n",
    "\n",
    "# Create a DataFrame to store the one-hot encoded tags\n",
    "\n",
    "one_hot_tags_df = pd.DataFrame(0, index=encoded_df.index, columns=list(unique_tags))\n",
    "\n",
    "# Iterate over each row and set the corresponding tag values to 1\n",
    "\n",
    "for i, tags_list in enumerate(encoded_df['tags']):\n",
    "    if tags_list is not None:\n",
    "        for tag in tags_list:\n",
    "            one_hot_tags_df.at[i, tag] = 1\n",
    "\n",
    "# Concatenate the one-hot encoded tags DataFrame with the original DataFrame\n",
    "\n",
    "encoded_df = pd.concat([encoded_df, one_hot_tags_df], axis=1)\n",
    "\n",
    "# Drop the original 'tags' column \n",
    "encoded_df.drop('tags', axis=1, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1972427617.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>community</th>\n",
       "      <th>virtual_tours</th>\n",
       "      <th>...</th>\n",
       "      <th>Iron Valley Real Estate of Central PA - Carlisle Office</th>\n",
       "      <th>Iron Valley Real Estate Of Central Pa</th>\n",
       "      <th>Bhhs Utah Properties - Sv</th>\n",
       "      <th>Summit Sotheby's International Realty</th>\n",
       "      <th>Better Homes and Gardens Real Estate Metro Brokers</th>\n",
       "      <th>BancWise Realty</th>\n",
       "      <th>Terry Howe &amp; Associates, Inc</th>\n",
       "      <th>Howard Hanna</th>\n",
       "      <th>Berkshire Hathaway HomeServices New England Properties - Farmington</th>\n",
       "      <th>RSR REALTORS, LLC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        last_update_date                                          permalink  \\\n",
       "5   2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "12  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "18  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "23  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "27  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "\n",
       "   status                    list_date open_houses  list_price property_id  \\\n",
       "5    sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "12   sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "18   sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "23   sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "27   sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "\n",
       "   photos community virtual_tours  ...  \\\n",
       "5    None      None          None  ...   \n",
       "12   None      None          None  ...   \n",
       "18   None      None          None  ...   \n",
       "23   None      None          None  ...   \n",
       "27   None      None          None  ...   \n",
       "\n",
       "   Iron Valley Real Estate of Central PA - Carlisle Office  \\\n",
       "5                                                   0        \n",
       "12                                                  0        \n",
       "18                                                  0        \n",
       "23                                                  0        \n",
       "27                                                  0        \n",
       "\n",
       "    Iron Valley Real Estate Of Central Pa Bhhs Utah Properties - Sv  \\\n",
       "5                                       0                         0   \n",
       "12                                      0                         0   \n",
       "18                                      0                         0   \n",
       "23                                      0                         0   \n",
       "27                                      0                         0   \n",
       "\n",
       "   Summit Sotheby's International Realty  \\\n",
       "5                                      0   \n",
       "12                                     0   \n",
       "18                                     0   \n",
       "23                                     0   \n",
       "27                                     0   \n",
       "\n",
       "   Better Homes and Gardens Real Estate Metro Brokers BancWise Realty  \\\n",
       "5                                                   0               0   \n",
       "12                                                  0               0   \n",
       "18                                                  0               0   \n",
       "23                                                  0               0   \n",
       "27                                                  0               0   \n",
       "\n",
       "   Terry Howe & Associates, Inc Howard Hanna  \\\n",
       "5                             0            0   \n",
       "12                            0            0   \n",
       "18                            0            0   \n",
       "23                            0            0   \n",
       "27                            0            0   \n",
       "\n",
       "    Berkshire Hathaway HomeServices New England Properties - Farmington  \\\n",
       "5                                                   0                     \n",
       "12                                                  0                     \n",
       "18                                                  0                     \n",
       "23                                                  0                     \n",
       "27                                                  0                     \n",
       "\n",
       "    RSR REALTORS, LLC  \n",
       "5                   0  \n",
       "12                  0  \n",
       "18                  0  \n",
       "23                  0  \n",
       "27                  0  \n",
       "\n",
       "[5 rows x 523 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to flatten the 'branding' column\n",
    "\n",
    "def flatten_branding(row):\n",
    "    branding_info = []\n",
    "    try:\n",
    "        for item in row:\n",
    "            if isinstance(item, dict):\n",
    "                branding_info.append(item['name'])\n",
    "            elif isinstance(item, list):\n",
    "                for sub_item in item:\n",
    "                    if isinstance(sub_item, dict):\n",
    "                        branding_info.append(sub_item['name'])\n",
    "            elif pd.isna(item):  \n",
    "                branding_info.append(None)\n",
    "            elif isinstance(item, float):  \n",
    "                pass\n",
    "    except TypeError:  \n",
    "        pass\n",
    "    return branding_info\n",
    "\n",
    "# Apply the flatten_branding function to each row to get a list of all brand names\n",
    "\n",
    "encoded_df['branding_info'] = encoded_df['branding'].apply(flatten_branding)\n",
    "\n",
    "# Drop the original 'branding' column\n",
    "\n",
    "encoded_df.drop(columns=['branding'], inplace=True)\n",
    "\n",
    "# Flatten the list of branding_info and extract unique brand names\n",
    "\n",
    "unique_brands = set()\n",
    "for branding_info in encoded_df['branding_info']:\n",
    "    if branding_info is not None:\n",
    "        unique_brands.update(branding_info)\n",
    "\n",
    "# Perform one-hot encoding for unique brand names\n",
    "\n",
    "for brand in unique_brands:\n",
    "    encoded_df[brand] = encoded_df['branding_info'].apply(lambda x: 1 if x is not None and brand in x else 0)\n",
    "\n",
    "# Drop the intermediate 'branding_info' column\n",
    "encoded_df.drop(columns=['branding_info'], inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>community</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>Iron Valley Real Estate of Central PA - Carlisle Office</th>\n",
       "      <th>Iron Valley Real Estate Of Central Pa</th>\n",
       "      <th>Bhhs Utah Properties - Sv</th>\n",
       "      <th>Summit Sotheby's International Realty</th>\n",
       "      <th>Better Homes and Gardens Real Estate Metro Brokers</th>\n",
       "      <th>BancWise Realty</th>\n",
       "      <th>Terry Howe &amp; Associates, Inc</th>\n",
       "      <th>Howard Hanna</th>\n",
       "      <th>Berkshire Hathaway HomeServices New England Properties - Farmington</th>\n",
       "      <th>RSR REALTORS, LLC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        last_update_date                                          permalink  \\\n",
       "5   2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "12  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "18  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "23  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "27  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "\n",
       "   status                    list_date open_houses  list_price property_id  \\\n",
       "5    sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "12   sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "18   sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "23   sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "27   sold  2023-08-21T21:01:22.000000Z        None    415000.0  7412309719   \n",
       "\n",
       "   community  listing_id  price_reduced_amount  ...  \\\n",
       "5       None  2958925334                   NaN  ...   \n",
       "12      None  2958925334                   NaN  ...   \n",
       "18      None  2958925334                   NaN  ...   \n",
       "23      None  2958925334                   NaN  ...   \n",
       "27      None  2958925334                   NaN  ...   \n",
       "\n",
       "   Iron Valley Real Estate of Central PA - Carlisle Office  \\\n",
       "5                                                   0        \n",
       "12                                                  0        \n",
       "18                                                  0        \n",
       "23                                                  0        \n",
       "27                                                  0        \n",
       "\n",
       "   Iron Valley Real Estate Of Central Pa Bhhs Utah Properties - Sv  \\\n",
       "5                                      0                         0   \n",
       "12                                     0                         0   \n",
       "18                                     0                         0   \n",
       "23                                     0                         0   \n",
       "27                                     0                         0   \n",
       "\n",
       "   Summit Sotheby's International Realty  \\\n",
       "5                                      0   \n",
       "12                                     0   \n",
       "18                                     0   \n",
       "23                                     0   \n",
       "27                                     0   \n",
       "\n",
       "   Better Homes and Gardens Real Estate Metro Brokers BancWise Realty  \\\n",
       "5                                                   0               0   \n",
       "12                                                  0               0   \n",
       "18                                                  0               0   \n",
       "23                                                  0               0   \n",
       "27                                                  0               0   \n",
       "\n",
       "    Terry Howe & Associates, Inc  Howard Hanna  \\\n",
       "5                              0             0   \n",
       "12                             0             0   \n",
       "18                             0             0   \n",
       "23                             0             0   \n",
       "27                             0             0   \n",
       "\n",
       "   Berkshire Hathaway HomeServices New England Properties - Farmington  \\\n",
       "5                                                   0                    \n",
       "12                                                  0                    \n",
       "18                                                  0                    \n",
       "23                                                  0                    \n",
       "27                                                  0                    \n",
       "\n",
       "    RSR REALTORS, LLC  \n",
       "5                   0  \n",
       "12                  0  \n",
       "18                  0  \n",
       "23                  0  \n",
       "27                  0  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop irellevant columns\n",
    "\n",
    "# Drop the 'photos' column and 'other_listings.rdc' column\n",
    "\n",
    "encoded_df.drop(columns=['photos', 'virtual_tours'], inplace=True)\n",
    "\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\403460919.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'None' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  encoded_df.fillna('None', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>community</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>Iron Valley Real Estate of Central PA - Carlisle Office</th>\n",
       "      <th>Iron Valley Real Estate Of Central Pa</th>\n",
       "      <th>Bhhs Utah Properties - Sv</th>\n",
       "      <th>Summit Sotheby's International Realty</th>\n",
       "      <th>Better Homes and Gardens Real Estate Metro Brokers</th>\n",
       "      <th>BancWise Realty</th>\n",
       "      <th>Terry Howe &amp; Associates, Inc</th>\n",
       "      <th>Howard Hanna</th>\n",
       "      <th>Berkshire Hathaway HomeServices New England Properties - Farmington</th>\n",
       "      <th>RSR REALTORS, LLC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        last_update_date                                          permalink  \\\n",
       "5   2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "12  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "18  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "23  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "27  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "\n",
       "   status                    list_date open_houses list_price property_id  \\\n",
       "5    sold  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719   \n",
       "12   sold  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719   \n",
       "18   sold  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719   \n",
       "23   sold  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719   \n",
       "27   sold  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719   \n",
       "\n",
       "   community  listing_id price_reduced_amount  ...  \\\n",
       "5       None  2958925334                 None  ...   \n",
       "12      None  2958925334                 None  ...   \n",
       "18      None  2958925334                 None  ...   \n",
       "23      None  2958925334                 None  ...   \n",
       "27      None  2958925334                 None  ...   \n",
       "\n",
       "   Iron Valley Real Estate of Central PA - Carlisle Office  \\\n",
       "5                                                   0        \n",
       "12                                                  0        \n",
       "18                                                  0        \n",
       "23                                                  0        \n",
       "27                                                  0        \n",
       "\n",
       "   Iron Valley Real Estate Of Central Pa Bhhs Utah Properties - Sv  \\\n",
       "5                                      0                         0   \n",
       "12                                     0                         0   \n",
       "18                                     0                         0   \n",
       "23                                     0                         0   \n",
       "27                                     0                         0   \n",
       "\n",
       "   Summit Sotheby's International Realty  \\\n",
       "5                                      0   \n",
       "12                                     0   \n",
       "18                                     0   \n",
       "23                                     0   \n",
       "27                                     0   \n",
       "\n",
       "   Better Homes and Gardens Real Estate Metro Brokers BancWise Realty  \\\n",
       "5                                                   0               0   \n",
       "12                                                  0               0   \n",
       "18                                                  0               0   \n",
       "23                                                  0               0   \n",
       "27                                                  0               0   \n",
       "\n",
       "   Terry Howe & Associates, Inc Howard Hanna  \\\n",
       "5                             0            0   \n",
       "12                            0            0   \n",
       "18                            0            0   \n",
       "23                            0            0   \n",
       "27                            0            0   \n",
       "\n",
       "   Berkshire Hathaway HomeServices New England Properties - Farmington  \\\n",
       "5                                                   0                    \n",
       "12                                                  0                    \n",
       "18                                                  0                    \n",
       "23                                                  0                    \n",
       "27                                                  0                    \n",
       "\n",
       "   RSR REALTORS, LLC  \n",
       "5                  0  \n",
       "12                 0  \n",
       "18                 0  \n",
       "23                 0  \n",
       "27                 0  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaN values with 'None' for all \n",
    "\n",
    "encoded_df.fillna('None', inplace=True)\n",
    "\n",
    "encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1131935107.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df['status_sold'] = (encoded_df['status'] == 'sold').astype(int)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\1131935107.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df['status_for_sale'] = (encoded_df['status'] == 'for sale').astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>permalink</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>community</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>matterport</th>\n",
       "      <th>...</th>\n",
       "      <th>Bhhs Utah Properties - Sv</th>\n",
       "      <th>Summit Sotheby's International Realty</th>\n",
       "      <th>Better Homes and Gardens Real Estate Metro Brokers</th>\n",
       "      <th>BancWise Realty</th>\n",
       "      <th>Terry Howe &amp; Associates, Inc</th>\n",
       "      <th>Howard Hanna</th>\n",
       "      <th>Berkshire Hathaway HomeServices New England Properties - Farmington</th>\n",
       "      <th>RSR REALTORS, LLC</th>\n",
       "      <th>status_sold</th>\n",
       "      <th>status_for_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 522 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        last_update_date                                          permalink  \\\n",
       "5   2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "12  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "18  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "23  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "27  2023-08-04T22:49:14Z  11909-Glacier-Hwy-Apt-105_Juneau_AK_99801_M741...   \n",
       "\n",
       "                      list_date open_houses list_price property_id community  \\\n",
       "5   2023-08-21T21:01:22.000000Z        None   415000.0  7412309719      None   \n",
       "12  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719      None   \n",
       "18  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719      None   \n",
       "23  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719      None   \n",
       "27  2023-08-21T21:01:22.000000Z        None   415000.0  7412309719      None   \n",
       "\n",
       "    listing_id price_reduced_amount matterport  ... Bhhs Utah Properties - Sv  \\\n",
       "5   2958925334                 None      False  ...                         0   \n",
       "12  2958925334                 None      False  ...                         0   \n",
       "18  2958925334                 None      False  ...                         0   \n",
       "23  2958925334                 None      False  ...                         0   \n",
       "27  2958925334                 None      False  ...                         0   \n",
       "\n",
       "   Summit Sotheby's International Realty  \\\n",
       "5                                      0   \n",
       "12                                     0   \n",
       "18                                     0   \n",
       "23                                     0   \n",
       "27                                     0   \n",
       "\n",
       "   Better Homes and Gardens Real Estate Metro Brokers BancWise Realty  \\\n",
       "5                                                   0               0   \n",
       "12                                                  0               0   \n",
       "18                                                  0               0   \n",
       "23                                                  0               0   \n",
       "27                                                  0               0   \n",
       "\n",
       "   Terry Howe & Associates, Inc Howard Hanna  \\\n",
       "5                             0            0   \n",
       "12                            0            0   \n",
       "18                            0            0   \n",
       "23                            0            0   \n",
       "27                            0            0   \n",
       "\n",
       "   Berkshire Hathaway HomeServices New England Properties - Farmington  \\\n",
       "5                                                   0                    \n",
       "12                                                  0                    \n",
       "18                                                  0                    \n",
       "23                                                  0                    \n",
       "27                                                  0                    \n",
       "\n",
       "   RSR REALTORS, LLC status_sold status_for_sale  \n",
       "5                  0           1               0  \n",
       "12                 0           1               0  \n",
       "18                 0           1               0  \n",
       "23                 0           1               0  \n",
       "27                 0           1               0  \n",
       "\n",
       "[5 rows x 522 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the 'status' \n",
    "\n",
    "encoded_df['status_sold'] = (encoded_df['status'] == 'sold').astype(int)\n",
    "encoded_df['status_for_sale'] = (encoded_df['status'] == 'for sale').astype(int)\n",
    "\n",
    "# Drop the original 'status' column\n",
    "\n",
    "encoded_df.drop(columns=['status'], inplace=True)\n",
    "\n",
    "encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\3659094003.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[['address', 'city', 'state', 'zip_code', 'unique_identifier']] = encoded_df['permalink'].str.split('_', expand=True)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\3659094003.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[['address', 'city', 'state', 'zip_code', 'unique_identifier']] = encoded_df['permalink'].str.split('_', expand=True)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\3659094003.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[['address', 'city', 'state', 'zip_code', 'unique_identifier']] = encoded_df['permalink'].str.split('_', expand=True)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\3659094003.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[['address', 'city', 'state', 'zip_code', 'unique_identifier']] = encoded_df['permalink'].str.split('_', expand=True)\n",
      "C:\\Users\\turab\\AppData\\Local\\Temp\\ipykernel_16660\\3659094003.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df[['address', 'city', 'state', 'zip_code', 'unique_identifier']] = encoded_df['permalink'].str.split('_', expand=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>community</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>matterport</th>\n",
       "      <th>primary_photo.href</th>\n",
       "      <th>...</th>\n",
       "      <th>Terry Howe &amp; Associates, Inc</th>\n",
       "      <th>Howard Hanna</th>\n",
       "      <th>Berkshire Hathaway HomeServices New England Properties - Farmington</th>\n",
       "      <th>RSR REALTORS, LLC</th>\n",
       "      <th>status_sold</th>\n",
       "      <th>status_for_sale</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>99801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>99801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>99801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>99801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-08-04T22:49:14Z</td>\n",
       "      <td>2023-08-21T21:01:22.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>7412309719</td>\n",
       "      <td>None</td>\n",
       "      <td>2958925334</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11909-Glacier-Hwy-Apt-105</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>99801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        last_update_date                    list_date open_houses list_price  \\\n",
       "5   2023-08-04T22:49:14Z  2023-08-21T21:01:22.000000Z        None   415000.0   \n",
       "12  2023-08-04T22:49:14Z  2023-08-21T21:01:22.000000Z        None   415000.0   \n",
       "18  2023-08-04T22:49:14Z  2023-08-21T21:01:22.000000Z        None   415000.0   \n",
       "23  2023-08-04T22:49:14Z  2023-08-21T21:01:22.000000Z        None   415000.0   \n",
       "27  2023-08-04T22:49:14Z  2023-08-21T21:01:22.000000Z        None   415000.0   \n",
       "\n",
       "   property_id community  listing_id price_reduced_amount matterport  \\\n",
       "5   7412309719      None  2958925334                 None      False   \n",
       "12  7412309719      None  2958925334                 None      False   \n",
       "18  7412309719      None  2958925334                 None      False   \n",
       "23  7412309719      None  2958925334                 None      False   \n",
       "27  7412309719      None  2958925334                 None      False   \n",
       "\n",
       "   primary_photo.href  ... Terry Howe & Associates, Inc Howard Hanna  \\\n",
       "5                None  ...                            0            0   \n",
       "12               None  ...                            0            0   \n",
       "18               None  ...                            0            0   \n",
       "23               None  ...                            0            0   \n",
       "27               None  ...                            0            0   \n",
       "\n",
       "   Berkshire Hathaway HomeServices New England Properties - Farmington  \\\n",
       "5                                                   0                    \n",
       "12                                                  0                    \n",
       "18                                                  0                    \n",
       "23                                                  0                    \n",
       "27                                                  0                    \n",
       "\n",
       "   RSR REALTORS, LLC status_sold status_for_sale                    address  \\\n",
       "5                  0           1               0  11909-Glacier-Hwy-Apt-105   \n",
       "12                 0           1               0  11909-Glacier-Hwy-Apt-105   \n",
       "18                 0           1               0  11909-Glacier-Hwy-Apt-105   \n",
       "23                 0           1               0  11909-Glacier-Hwy-Apt-105   \n",
       "27                 0           1               0  11909-Glacier-Hwy-Apt-105   \n",
       "\n",
       "      city state zip_code  \n",
       "5   Juneau    AK    99801  \n",
       "12  Juneau    AK    99801  \n",
       "18  Juneau    AK    99801  \n",
       "23  Juneau    AK    99801  \n",
       "27  Juneau    AK    99801  \n",
       "\n",
       "[5 rows x 525 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the 'permalink' column into separate columns\n",
    "encoded_df[['address', 'city', 'state', 'zip_code', 'unique_identifier']] = encoded_df['permalink'].str.split('_', expand=True)\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "encoded_df.drop(columns=['permalink', 'unique_identifier'], inplace=True)\n",
    "\n",
    "encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_update_date  list_date  open_houses  list_price  property_id  \\\n",
      "5                  1         52            0         137          223   \n",
      "12                 1         52            0         137          223   \n",
      "18                 1         52            0         137          223   \n",
      "23                 1         52            0         137          223   \n",
      "27                 1         52            0         137          223   \n",
      "\n",
      "    community  listing_id  price_reduced_amount  matterport  \\\n",
      "5           0          56                    51           0   \n",
      "12          0          56                    51           0   \n",
      "18          0          56                    51           0   \n",
      "23          0          56                    51           0   \n",
      "27          0          56                    51           0   \n",
      "\n",
      "    primary_photo.href  ...  Terry Howe & Associates, Inc  Howard Hanna  \\\n",
      "5                    0  ...                             0             0   \n",
      "12                   0  ...                             0             0   \n",
      "18                   0  ...                             0             0   \n",
      "23                   0  ...                             0             0   \n",
      "27                   0  ...                             0             0   \n",
      "\n",
      "    Berkshire Hathaway HomeServices New England Properties - Farmington  \\\n",
      "5                                                   0                     \n",
      "12                                                  0                     \n",
      "18                                                  0                     \n",
      "23                                                  0                     \n",
      "27                                                  0                     \n",
      "\n",
      "    RSR REALTORS, LLC  status_sold  status_for_sale  address  city  state  \\\n",
      "5                   0            1                0       19    27      1   \n",
      "12                  0            1                0       19    27      1   \n",
      "18                  0            1                0       19    27      1   \n",
      "23                  0            1                0       19    27      1   \n",
      "27                  0            1                0       19    27      1   \n",
      "\n",
      "    zip_code  \n",
      "5        171  \n",
      "12       171  \n",
      "18       171  \n",
      "23       171  \n",
      "27       171  \n",
      "\n",
      "[5 rows x 525 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder from scikit-learn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Iterate over each column\n",
    "\n",
    "for column in encoded_df.columns:\n",
    "    # Check if the column is not numeric\n",
    "\n",
    "    if encoded_df[column].dtype != 'int' and encoded_df[column].dtype != 'float':\n",
    "        # Convert non-numeric values to string\n",
    "\n",
    "        encoded_df[column] = encoded_df[column].astype(str)\n",
    "        # Encode the column\n",
    "\n",
    "        encoded_df[column] = label_encoder.fit_transform(encoded_df[column])\n",
    "\n",
    "# Check the encoded dataframe\n",
    "\n",
    "print(encoded_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sales will vary drastically between cities and states.  Is there a way to keep information about which city it is without OHE such as using central tendency?\n",
    "- Could we label encode or ordinal encode?  Yes, but this may have undesirable effects, giving nominal data ordinal values.\n",
    "- If you replace cities or states with numerical values, make sure that the data is split so that we don't leak data into the training selection. This is a great time to train test split. Compute on the training data, and join these values to the test data\n",
    "- Drop columns that aren't needed.\n",
    "- Don't keep the list price because it will be too close to the sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2096, 524)\n",
      "X_test shape: (524, 524)\n",
      "y_train shape: (2096,)\n",
      "y_test shape: (524,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = encoded_df.drop('list_price', axis=1)\n",
    "y = encoded_df['list_price']\n",
    "\n",
    "# Perform train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the train and test sets\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV files\n",
    "\n",
    "X_train.to_csv('x_train.csv', index=False)\n",
    "X_test.to_csv('x_test.csv', index=False)\n",
    "y_train_df.to_csv('y_train.csv', index=False)\n",
    "y_test_df.to_csv('y_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRETCH**\n",
    "\n",
    "- You're not limited to just using the data provided to you. Think/ do some research about other features that might be useful to predict housing prices. \n",
    "- Can you import and join this data? Make sure you do any necessary preprocessing and make sure it is joined correctly.\n",
    "- Example suggestion: could mortgage interest rates in the year of the listing affect the price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, join and preprocess new data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember all of the EDA that you've been learning about?  Now is a perfect time for it!\n",
    "- Look at distributions of numerical variables to see the shape of the data and detect outliers.\n",
    "- Scatterplots of a numerical variable and the target go a long way to show correlations.\n",
    "- A heatmap will help detect highly correlated features, and we don't want these.\n",
    "- Is there any overlap in any of the features? (redundant information, like number of this or that room...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform EDA here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is a great time to scale the data and save it once it's preprocessed.\n",
    "- You can save it in your data folder, but you may want to make a new `processed/` subfolder to keep it organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
